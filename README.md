# Fake News Classifier üì∞ü§ñ  

A high-accuracy Fake News Classifier (F1 score: **0.9913**) built using transformer models. This project enables **real-time classification** of news articles and supports **batch inference** through a script.
## üìå Release Notes (v1.0.0)
This is the first official release of the **Fake News Classifier**. Key features:
- **Transformer-based classifier** with high accuracy (**F1 score: 0.9913**)
- **Supports real-time inference** for single news articles
- **Batch classification** using CSV files
- **Streamlit web app** for interactive use
- **Automated unit tests** for validation and reliability

## üì• Input & üì§ Output
### ‚úÖ Supported Inputs:
- **Single news article** (string)
- **CSV file** with a `text` column containing multiple articles

### üîç Output:
- **Prediction**: `Real` or `Fake`
- **Confidence Score**: Probability of prediction accuracy (0.0 - 1.0)

## üöÄ Features  
- **High Accuracy:** Achieves an **F1 score of 0.9913** using MPNET.  
- **Comprehensive Dataset:** Combines scraped real news, LLM-generated fake articles, and Kaggle datasets.  
- **Flexible Inference:**  
  - Classify a **single article** via command line or the Streamlit app.  
  - Process **multiple articles from a CSV file** and receive structured output.  
- **Automated Testing:** Includes **unit tests** for reliability.  

## üìä Model & Approach  
- **Data Collection:**  
  - Scraped real news articles from verified sources.  
  - Generated news using **LLMs**.  
  - Integrated additional data from **two Kaggle datasets**.  
- **Model Training:**  
  - Compared **BERT** and **MPNET**, selecting MPNET for its superior performance.  
- **Deployment:**  
  - Website using `streamlit` app for inference with either a single article or a `.csv` file.  
## üìÇ Files in the Repository

- `start.py` ‚Äì The main script for inference (single article & batch processing).
- `unit_test.py` ‚Äì Contains automated tests for model validation.
- `run.py` ‚Äì Launches the Streamlit web application.
- `requirements.txt` ‚Äì Lists all dependencies needed to run the project.
- `saved_model/` ‚Äì Contains the trained model and tokenizer files.

## üõ† Installation & Usage  

### 1Ô∏è‚É£ Clone the Repository  
```bash
git clone https://github.com/youssefreda02/Fake_News_classifier.git
cd Fake_News_classifier
pip install -r requirements.txt
```
## 2Ô∏è‚É£ Running Unit Tests  
To verify the functionality and accuracy of the model, **unit tests** are included. Run them with:  
```bash
python -m unittest unit_test.py
```
After all tests are executed, a success message will be printed for each passed test.
Example output:
```bash
‚úÖ test_predict_real passed!
‚úÖ test_predict_fake passed!
‚úÖ test_empty_string passed!
‚úÖ test_whitespace_string passed!
‚úÖ test_non_string_input passed!
‚úÖ test_empty_csv_file passed!
‚úÖ test_csv_without_text_column passed!
‚úÖ test_invalid_csv_format passed!
‚úÖ test_non_existent_csv_file passed!
```

### 3Ô∏è‚É£ Running the Streamlit App  
To launch the web-based classifier, use:  
```bash
streamlit run run.py
```
This will open a web interface where you can input an article and receive classification results.  

### 3Ô∏è‚É£ Command Line Inference  
To classify news via the command line, run:  
```bash
python start.py
```
The script will prompt you to choose:
- `single` to classify one article interactively.
- `file` to classify articles from a CSV file.

#### Input Handling:
##### üß™ Test Cases

The following test scenarios are covered in the unit tests:

| **Category**           | **Test Case**                                             | **Expected Behavior** |
|-----------------------|--------------------------------------------------------|----------------------|
| **Model Loading**     | Load a valid model                                      | Model loads successfully |
|                      | Load a non-existent model                               | Raises `RuntimeError` |
| **Text Classification** | Classify real news                                   | Returns `"Real"` label |
|                      | Classify fake news                                    | Returns `"Fake"` label |
|                      | Predict empty string                                  | Returns `"Invalid input"` with confidence `0.0` |
|                      | Predict whitespace string                             | Returns `"Invalid input"` with confidence `0.0` |
|                      | Predict non-string input (e.g., integer)              | Raises `ValueError` |
|                      | Predict with `None` input                             | Raises `ValueError` |
|                      | Predict extremely long text                           | Successfully processes and classifies |
| **CSV Processing**    | Inference from a valid CSV                            | Generates an output file |
|                      | Inference from an empty CSV                           | Raises `ValueError` |
|                      | Inference from CSV missing the `text` column          | Raises `ValueError` |
|                      | Inference from a non-CSV file                         | Raises `ValueError` with "Please provide a valid CSV file." |
|                      | Inference from a non-existent file                    | Raises `FileNotFoundError` |
|                      | Inference from CSV with `NaN` values                  | Handles missing values correctly |
|                      | Inference from CSV with mixed data types              | Raises `ValueError` |


#### CSV File Processing:
- The CSV file should contain a `text` column.
- When a CSV file is provided, the script adds **two new columns**:
  - **`prediction`**: The classification result (Real/Fake)
  - **`confidence`**: The model‚Äôs confidence score

#### Example CSV Format (Before Processing):
| id | title               | text               |
|----|---------------------|--------------------|
| 1  | Example Headline 1 | Example article 1 |
| 2  | Example Headline 2 | Example article 2 |

#### Example CSV Output (After Processing):
| id | title               | text               | prediction | confidence |
|----|---------------------|--------------------|------------|------------|
| 1  | Example Headline 1 | Example article 1 | Fake       | 0.98       |
| 2  | Example Headline 2 | Example article 2 | Real       | 0.95       |

## üé® Streamlit App Screenshot

## üî• Future Enhancements  
- Implementing a **confidence score visualization**.
- Expanding the dataset for better generalization.

## ü§ù Contributing  
Contributions are welcome! Please open an issue or submit a pull request.

